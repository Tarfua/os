---
alwaysApply: true
---

# Next-Generation General Purpose OS Architecture (Linux-Inspired, Clean-Slate Design)

## 1. Design Goals

1. Security-first by architecture, not add-ons  
2. Strong isolation between components (fault & compromise containment)  
3. High performance on servers *and* low-latency desktops  
4. Hardware vendor–friendly driver model  
5. Long-term maintainability (controlled complexity growth)  
6. Backward compatibility with POSIX as a *layer*, not a constraint  

---

## 2. High-Level Architecture Overview

```
+-----------------------------------------------------------+
|                    User Applications                      |
|  (POSIX layer, native apps, containers, runtimes)         |
+---------------------------+-------------------------------+
|        System Services    |     Compatibility Services    |
| (FS mgr, net mgr, policy) | (POSIX, legacy Linux ABI)     |
+---------------------------+-------------------------------+
|        User-Space Drivers & Subsystems (Isolated)         |
|  Filesystems | Network stacks | GPU | USB | Storage       |
+---------------------------+-------------------------------+
|            Microkernel Core (Minimal Trusted Base)        |
|  Scheduler | IPC | Memory Mgmt | Capabilities | IOMMU     |
+-----------------------------------------------------------+
|                         Hardware                          |
+-----------------------------------------------------------+
```

---

## 3. Kernel Architecture

### 3.1 Microkernel Core Responsibilities Only

The kernel must be **small, auditable, and stable**. It contains only:

- Thread scheduling (preemptive, priority & latency aware)
- Virtual memory management (address spaces, mapping, paging)
- Inter-process communication (fast, capability-checked IPC)
- Capability-based security enforcement
- Interrupt routing and basic hardware abstraction
- IOMMU management for DMA isolation

Everything else runs outside the kernel.

### 3.2 What Is Explicitly NOT in the Kernel

- Filesystem implementations  
- Network protocol stacks  
- Device drivers  
- Graphics stacks  
- USB/Bluetooth stacks  

These live in isolated user-space services.

---

## 4. Security Model (Foundational)

### 4.1 No Global "root"

There is **no all-powerful superuser**.

Instead:
- Every process runs with a set of **capabilities**
- Capabilities are unforgeable tokens granting specific rights:
  - Access to a device
  - Ability to map memory
  - Permission to talk to a service
  - Network binding rights

If a process does not have a capability, the operation is impossible.

### 4.2 Capability Properties

- Fine-grained (not “admin vs user”)
- Delegatable (a process can pass limited rights to another)
- Revocable (system can withdraw rights)
- Namespaced (containers = capability subsets)

### 4.3 Mandatory Isolation by Default

- Every service runs in its own address space
- Drivers cannot access arbitrary memory
- Filesystem services cannot access raw devices without explicit capability
- Network stacks cannot read files unless granted

---

## 5. Driver Model

### 5.1 Drivers Run in User Space

All drivers are isolated processes:

- One driver crash ≠ system crash
- Compromised driver cannot directly own the kernel
- Drivers communicate with the kernel via IPC

### 5.2 Hardware Access Rules

- DMA only via IOMMU mappings explicitly granted
- No direct physical memory access outside assigned regions
- Interrupts delivered to driver processes through kernel mediation

### 5.3 Stable Driver ABI

The OS provides:

- Versioned, stable driver interface
- Long-term binary compatibility for drivers
- Strict interface boundaries to prevent kernel coupling

This encourages hardware vendor support.

---

## 6. Filesystem Architecture

### 6.1 Filesystems as Services

Each filesystem is a separate user-space server:

- Local FS (e.g., modern CoW FS)
- Network FS
- Encrypted FS layers

They expose a unified VFS protocol to the system.

### 6.2 Structured Kernel Interface (No Text Pseudo-Files)

No `/proc` or `/sys` text parsing.

Instead:
- Typed system calls
- Structured queries
- Versioned object models

---

## 7. Networking Architecture

### 7.1 Network Stacks in User Space

- Multiple network stacks can coexist (performance vs security variants)
- Crashes in network code do not crash the kernel
- Sandboxed protocol implementations

### 7.2 Secure by Default

- Raw packet access requires explicit capability
- Network services run with minimal privileges
- Fine-grained firewalling integrated with capability model

---

## 8. Process & IPC Model

### 8.1 IPC Is the Core Primitive

Everything is a service accessed via IPC:

- Filesystem operations
- Device control
- Network communication
- System management

IPC must be:
- Fast (shared memory + message passing)
- Capability-checked
- Observable for debugging

### 8.2 Service-Oriented OS

The OS behaves like a set of cooperating, isolated services rather than a monolithic blob.

---

## 9. Scheduling & Performance

### 9.1 Latency-Aware Scheduler

Scheduler designed for:

- Low-latency UI threads
- Real-time audio/video
- VR/AR workloads
- Traditional server throughput

Priority inheritance and deadline scheduling are first-class.

### 9.2 Performance Strategy

- Critical paths optimized with shared memory IPC
- Zero-copy data paths where safe
- User-space drivers allowed with fast kernel bypass mechanisms under strict control

---

## 10. Memory Safety Strategy

### 10.1 Safe Languages by Default

- Kernel written in a memory-safe systems language (e.g., Rust-like)
- Drivers strongly encouraged or required to use safe languages
- Unsafe code isolated and audited

### 10.2 Containing Unsafe Components

If unsafe code exists:
- It runs in isolated processes
- Damage is limited by capabilities and memory boundaries

---

## 11. Compatibility Layers

### 11.1 POSIX Compatibility as a Service

A dedicated compatibility layer provides:

- POSIX syscalls
- Traditional process model
- Signals, fork/exec semantics

Internally, these map to the new kernel primitives.

### 11.2 Legacy Linux ABI Layer (Optional)

A containerized compatibility subsystem may run:

- Recompiled Linux binaries
- Legacy software stacks

Without polluting the core architecture.

---

## 12. System Management Philosophy

- Core kernel: minimal, rarely changing, highly verified
- Most innovation happens in replaceable user-space services
- System components can be restarted independently
- Observability and introspection built into IPC and capability systems

---

## 13. Development & Testing Strategy (QEMU-Centric)

### 13.1 Primary Test Platform: QEMU

QEMU is the main development environment from the first boot instruction to a multi-service OS.

**Why QEMU is critical:**
- Hardware-independent early bring-up
- Full system emulation (CPU, memory, interrupts, devices)
- GDB remote debugging of kernel code
- Snapshotting and deterministic test setups
- CI-friendly automated boot testing

### 13.2 Early Boot Workflow

1. UEFI firmware (OVMF) used with QEMU  
2. Kernel loaded as an EFI application or via custom bootloader  
3. Serial output (`-serial stdio`) used as the primary debug channel  

Example launch pattern:

```
qemu-system-x86_64 \
  -machine q35 \
  -cpu qemu64 \
  -m 512M \
  -serial stdio \
  -drive if=pflash,format=raw,readonly=on,file=OVMF_CODE.fd \
  -drive format=raw,file=os.img
```

### 13.3 Kernel Debugging

QEMU supports source-level kernel debugging:

```
qemu-system-x86_64 -s -S ...
```

- `-S` pauses CPU at startup  
- `-s` opens a GDB server on port 1234  

This allows:
- Breakpoints in kernel code  
- Step-by-step execution  
- Register and memory inspection  

This is essential during:
- Memory manager bring-up  
- Scheduler debugging  
- IPC correctness validation  

### 13.4 Automated Testing

QEMU instances can be scripted to:
- Boot the OS
- Run a test service
- Report success via serial output

This enables regression testing of:
- IPC semantics
- Capability enforcement
- Scheduler fairness
- Memory isolation

---

## 14. Microkernel Development Roadmap

### Stage 1 — Bare-Metal Kernel Skeleton

Goal: Reach a stable execution environment.

Components:
- UEFI boot
- Long mode setup
- Interrupt descriptor table
- Basic physical and virtual memory mapping
- Serial debug output

Result: Kernel runs and handles timer interrupts.

---

### Stage 2 — Core Kernel Mechanisms

Goal: Build a minimal but correct microkernel core with strong isolation, preemptive multitasking, and controlled inter-process communication.

This stage is intentionally split into three sub-stages to avoid architectural coupling and uncontrolled complexity growth.

---

## Stage 2A — Execution & Isolation Primitives

Goal: Establish fundamental execution units and memory isolation without introducing scheduling policy or IPC.

### Components

#### Address Space Abstraction
- Introduce `AddressSpace` as a first-class kernel object.
- Each address space owns exactly one root page table (PML4).
- Kernel space is mapped into all address spaces (higher-half mapping).
- User space mappings are fully isolated per address space.

Constraints:
- No shared user mappings.
- No lazy mapping or copy-on-write.
- No demand paging.

Result:
- Kernel can create, destroy, and switch address spaces safely.

---

#### Thread Abstraction
- Introduce `Thread` as the minimal execution unit.
- A thread consists of:
  - CPU register context
  - Kernel stack
  - Associated address space
- Threads are independent of scheduling policy.

Constraints:
- No priorities.
- No signals.
- No TLS.
- No user-visible thread API.

Result:
- Kernel can create threads bound to specific address spaces.

---

#### Context Switching
- Implement low-level context switch routine.
- Switching includes:
  - Saving/restoring CPU registers
  - Switching CR3
  - Correct return via `iretq`

Constraints:
- No scheduler logic inside context switch.
- No preemption logic.

Result:
- Kernel can explicitly switch execution between threads.

---

### Stage 2A Result
- Multiple threads exist.
- Each thread executes in its own address space.
- Manual context switching is functional and stable.

---

## Stage 2B — Scheduling & Time

Goal: Introduce preemptive multitasking driven by timer interrupts, without IPC or high-level policies.

### Components

#### Thread States
- Define thread lifecycle states:
  - Runnable
  - Running
  - Blocked
  - Dead

Constraints:
- Blocked state has no reason attached.
- No sleeping or timeouts.

---

#### Scheduler Core
- Implement a minimal preemptive scheduler.
- Single run queue.
- Round-robin scheduling.
- One CPU only (no SMP support).

Constraints:
- No priorities.
- No load balancing.
- No per-core queues.

---

#### Timer-Driven Preemption
- Use hardware timer interrupt to trigger scheduling.
- Timer interrupt handler must:
  - Save current thread state
  - Invoke scheduler
  - Switch to next runnable thread

---

#### Preemption Control
- Introduce per-CPU preemption disable counter.
- Kernel critical sections must explicitly disable preemption.
- Interrupt disable is not a substitute for scheduler locking.

Constraints:
- No fine-grained locking model yet.

---

### Stage 2B Result
- Threads are preempted by timer interrupts.
- Kernel executes multiple threads safely.
- Scheduler is isolated from IPC and resource management logic.

---

## Stage 2C — IPC & Capability Core

Goal: Enable controlled communication and authority transfer between isolated execution contexts.

### Components

#### IPC Model
- Implement synchronous, blocking message passing.
- IPC operations:
  - `send(endpoint, message)`
  - `recv(endpoint)`

Constraints:
- No asynchronous IPC.
- No message queues.
- One sender and one receiver per endpoint.

---

#### IPC Messages
- Messages consist of:
  - Fixed-size word payload
  - Optional capability transfers

Constraints:
- No variable-sized messages.
- No shared memory payloads.

---

#### Endpoint Object
- Introduce `Endpoint` as an IPC rendezvous point.
- Endpoint holds:
  - At most one waiting sender
  - At most one waiting receiver

Constraints:
- One-to-one communication only.
- No broadcast or multicast.

---

#### Thread Blocking Semantics
- IPC operations directly manipulate thread states:
  - Sending thread blocks if no receiver.
  - Receiving thread blocks if no sender.
  - Successful match unblocks both.

---

#### Capability System (Initial Version)
- Introduce typed capabilities as unforgeable kernel references.
- Supported capability types:
  - Thread
  - AddressSpace
  - Endpoint

Constraints:
- No capability copying.
- No revocation.
- No delegation hierarchy.
- Capabilities can only be transferred via IPC.

---

### Stage 2C Result
- Multiple isolated processes communicate exclusively via IPC.
- Authority is explicitly represented and transferred.
- Kernel has no ambient authority outside capabilities.

---

## Overall Stage 2 Result

- Fully isolated address spaces.
- Preemptive multitasking.
- Synchronous IPC as the sole communication mechanism.
- Minimal capability-based security model.

Out of Scope:
- Shared memory
- Filesystems
- Drivers
- SMP
- Advanced scheduling policies
- Capability revocation

This stage establishes a clean, minimal microkernel foundation suitable for controlled extension in later stages.


---

### Stage 3 — Capability Enforcement

Goal: Security model becomes real.

Components:
- Capability objects in kernel
- Per-process capability spaces
- Capability transfer via IPC
- Access checks on all kernel operations

Result: No operation without explicit authority.

---

### Stage 4 — First User-Space System Services

Goal: Move policy out of kernel.

Services:
- Root system service (process spawning and capability distribution)
- Memory management policy service
- Logging/console service

Result: Kernel only provides mechanisms; services define behavior.

---

### Stage 5 — User-Space Driver Framework

Goal: Hardware access without kernel bloat.

Components:
- Interrupt delivery to user space
- IOMMU-backed DMA isolation
- Driver IPC interfaces

First drivers:
- Serial
- Timer
- RAM-backed block device

Result: Drivers can crash without crashing the system.

---

### Stage 6 — Filesystem Service

Goal: Persistent storage outside the kernel.

Components:
- VFS protocol over IPC
- RAM filesystem
- Block device integration

Result: Files are managed entirely in user space.

---

### Stage 7 — Networking Stack

Goal: Safe and replaceable networking.

Components:
- NIC driver in user space
- User-space TCP/IP stack
- Capability-controlled socket service

Result: Network failures do not compromise kernel stability.

---

### Stage 8 — POSIX Compatibility Layer

Goal: Practical software ecosystem support.

Components:
- POSIX syscall translation service
- Process model emulation
- Filesystem and socket mapping to native services

Result: Unix-style applications run without polluting kernel design.

---

## 15. Summary Philosophy

This system keeps from Linux:

- Unix process model (via compatibility)
- File and socket abstractions
- Open ecosystem and modularity

But fixes at the root:

- No monolithic trusted driver code
- No global superuser
- No text-based kernel control hacks
- No assumption that hardware or drivers are trustworthy

It is designed for a world where:
- Devices are hostile
- Isolation is mandatory
- Security and reliability outrank historical convenience
